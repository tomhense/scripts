#!/bin/python3
from __future__ import print_function
from selenium import webdriver
from selenium.webdriver.firefox.options import Options
import time
import argparse
import re
import sys
import os

def extractSource(url, scrollToEnd=False, sleep=None, headless=False):
	options = Options()
	options.page_load_stratergy = "normal"
	if headless:
		options.add_argument("--headless")


	browser=webdriver.Firefox(service_log_path=os.devnull, options=options)
	browser.get(url)
	while scrollToEnd:
		browser.execute_script("window.scrollBy(0,window.scrollMaxY)")
		time.sleep(1)
		scrollToEnd = browser.execute_script("return window.scrollY != window.scrollMaxY")
	if sleep:
		time.sleep(sleep)
	source = browser.page_source
	browser.close()
	return source

def isUrl(url):
	return re.match("http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", url) != None

def eprint(*args, **kwargs):
	print(*args, file=sys.stderr, **kwargs)

if __name__ == "__main__":
	parser = argparse.ArgumentParser(description="Extract source code from page (with js)")
	parser.add_argument("url", help="The url to extract the source from")
	parser.add_argument("--scroll", action="store_true", help="Scroll page to the end")
	parser.add_argument("--output", "-o", help="Output to file instead of stdout")
	#parser.add_argument("--enable-images", action="store_true", help="Disable the loading of all images")
	parser.add_argument("--sleep", type=int, help="Sleep n seconds before extracting source")
	parser.add_argument("--headless", action="store_true", help="Run headless")
	args = parser.parse_args()

	if isUrl(args.url):
		source = extractSource(
			args.url, 
			scrollToEnd=args.scroll, 
			sleep=args.sleep, 
			headless=args.headless
		)
		if args.output:
			with open(args.output, "w") as file:
				file.write(source)
		else:
			print(source)
	else:
		eprint("ERROR: Given url is not valid")
		exit(1)
